# generate crosswalks from region identifiers in the climate data to location_id1, location_id2 for each country
# doing so by taking a crosswalk generated by tracing back Trin's cleaning code,
# then read climate data files, take the identifier columns, and match the two (pretty manually for some countries)

import pandas as pd
import re
import cilpath
import geopandas as gpd

pd.set_option('display.max_columns', None)  # or 1000
pd.set_option('display.max_rows', None)  # or 1000
pd.set_option('display.max_colwidth', -1)  # or 199

paths = cilpath.Cilpath()
# this crosswalk is generated from here 
# https://gitlab.com/ClimateImpactLab/Impacts/gcp-labor/blob/GMFD/1_Cleaning/MasterMergeGMFD/IncomeMerge/generate_location_id_name_crosswalk.do
crosswalk_path = paths.DB + "/Global ACP/labor/1_preparation/climate_data/adm1_adm2_id_name_crosswalk.dta"
crosswalk = pd.read_stata(crosswalk_path)

countries = ["BRA","ESP","FRA","GBR","IND","MEX","USA"]
dt = {}
cw = {}
for iso in countries:
    dt[iso] = pd.read_stata("/shares/gcp/estimation/Labor/Climate_data/time_use_newvars/outputs/merged/" + iso + "/GMFD_spline_popwt_" + iso + ".dta")



# 

adm1_shp_path = "/shares/gcp/climate/_spatial_data/"
adm1_shp = {}


for iso in ['USA','IND','CHN']:
    adm1_shp[iso] = gpd.read_file(adm1_shp_path + iso + "/" + iso + "_adm1.shp")

adm1_shp['MEX'] = gpd.read_file(adm1_shp_path + "MEX/Ag_ESOC_shapefiles_Mexican States.shp")



# USA crosswalk

keys = {}

keys['USA'] = dt['USA'][['NAME_1','NAME_2']].drop_duplicates()

regex_alphabet = re.compile('[^a-zA-Z]')

def clean_keys_USA(x):
    x['location_name2'] = regex_alphabet.sub("", x['NAME_1'].lower())+ regex_alphabet.sub("", x['NAME_2'].lower())
    return x

keys["USA"] = keys["USA"].apply(lambda row: clean_keys_USA(row), axis = 1)
keys['USA'].loc[keys['USA'].NAME_2 == "District of Columbia", 'location_name2'] = "dcdc"
keys['USA'][keys['USA'].location_name2 == "dcdc"]

cw['USA'] = keys['USA'].merge(crosswalk[crosswalk.iso == 'USA'], 
                              on = ["location_name2"], 
                              how = "right")

# MEX crosswalk

keys['MEX'] = dt['MEX'][['NOM_ENT','NOM_MUN']].drop_duplicates()

def clean_keys_MEX(x):
    x['location_name1'] = x['NOM_ENT'].lower()
    x['location_name2'] = x['NOM_MUN'].lower()
    return x

keys["MEX"] = keys["MEX"].apply(lambda row: clean_keys_MEX(row), axis = 1)
cw['MEX'] = keys['MEX'].merge(crosswalk[crosswalk.iso == 'MEX'], 
                              on = ["location_name1", "location_name2"], 
                              how = "right")
cw['MEX']['NAME_1'] = cw['MEX']['NOM_ENT'] 

# IND crosswalk

dist_codes_IND = pd.read_csv(paths.DB + "/Global ACP/labor/1_preparation/climate_data/India_Census_1991_Districts.csv")[["DIST91_ID","NAME","STATE_UT"]]
keys['IND'] = dt['IND'][['DIST91_ID']].drop_duplicates().merge(dist_codes_IND, on = "DIST91_ID", how = "left")

def clean_keys_IND(x):
    x['location_name2'] = x['NAME'].lower()
    x['location_name1'] = x['STATE_UT'].lower().replace("_", " ")
    return x

keys["IND"] = keys["IND"].apply(lambda row: clean_keys_IND(row), axis = 1)

cw['IND'] = keys['IND'].merge(crosswalk[crosswalk.iso == 'IND'],
                  on = ["location_name1", "location_name2"], 
                  how = "right")
cw['IND']['NAME_1'] = cw['IND']['location_name1'].str.title()


# BRA crosswalk

keys['BRA'] = dt['BRA'][["NAME_1","NAME_2"]].drop_duplicates()

def clean_keys_BRA(x):
    x['location_name2'] = x['NAME_2'].lower().replace(" ", "_")
    return x
keys["BRA"] = keys["BRA"].apply(lambda row: clean_keys_BRA(row), axis = 1)
keys['BRA'].loc[keys['BRA'].NAME_2 == "So Paulo", 'location_name2'] = "sao_paulo"

cw['BRA'] = keys['BRA'].merge(crosswalk[crosswalk.iso == 'BRA'],
                  on = ["location_name2"], 
                  how = "right")


# FRA crosswalk

keys['FRA'] = pd.DataFrame(dt['FRA']['NAME_1'].drop_duplicates())
regex_alphabet_dash = re.compile('[^a-zA-Z-\']')

def clean_keys_FRA(x):
    x['location_name2'] = regex_alphabet_dash.sub("", x['NAME_1'].lower())
    return x

keys["FRA"] = keys["FRA"].apply(lambda row: clean_keys_FRA(row), axis = 1)
keys['FRA'].loc[keys['FRA'].NAME_1 == "Provence-Alpes-Côte d'Azur", 'location_name2'] = "provence-cted'azur-corse"

cw['FRA'] = keys['FRA'].merge(crosswalk[crosswalk.iso == 'FRA'],
                  on = ["location_name2"], 
                  how = "right")


# ESP crosswalk

keys['ESP'] = pd.DataFrame(dt['ESP']['NAME_1'].drop_duplicates())
clim_dic_ESP = {"Andalucía":1,
              "Aragón":2,
              "Cantabria":6,
              "Castilla-La Mancha":8,
              "Castilla y León":7,
              "Cataluña":9,
              "Ceuta y Melilla":18,
              "Comunidad de Madrid":13,
              "Comunidad Foral de Navarra":15,
              "Comunidad Valenciana":10,
              "Extremadura":11,
              "Galicia":12,
              "Islas Baleares":4,
              "Islas Canarias":5,
              "La Rioja":17,
              "País Vasco":16,
               "Principado de Asturias":3,
               "Región de Murcia":14
              }

time_dic_ESP = {
    "barcelona":9,
    "albacete":8,
    "navarra":15,
    "madrid":13,
    "corua(a)":12,
    "balears,illes":4,
    "almera":1,
    "huesca":2,
    "rioja,la":17,
    "alicante/alacant":10,
    "burgos":7,
    "guipzcoa":16,
    "murcia":14,
    "palmas,las":5,
    "asturias":3,
    "cantabria":6,
    "badajoz":11,
    "ceutaymelilla":18
}


keys["ESP"]['merge_code'] = keys["ESP"]['NAME_1'].map(clim_dic_ESP)
keys["ESP"]['location_name2'] = keys["ESP"]['merge_code'].map({v: k for k, v in time_dic_ESP.items()})
cw['ESP'] = keys['ESP'].merge(crosswalk[crosswalk.iso == 'ESP'],
                  on = ["location_name2"], 
                  how = "right")



# GBR crosswalk

keys['GBR'] = pd.DataFrame(dt['GBR']['ADMIN_NAME'].drop_duplicates())
clim_dic_GBR = {"North West":"north",
               "North East":"north",
               "Yorkshire and the Humber":"north",
               "West Midlands":"midlands",
               "East Midlands":"midlands",
               "East of England":"eastanglia",
               "Northern Ireland":"northernireland",
               "Scotland":"scotland",
               "South East and London":"southeastw/london",
               "South West":"southwest",
                "Wales":"wales"
               }
weights_dic_GBR = {"North West":0.474,
               "North East":0.178,
               "Yorkshire and the Humber":0.348,
               "West Midlands":0.442,
               "East Midlands":0.558,
               "East of England":1,
               "Northern Ireland":1,
               "Scotland":1,
               "South East and London":1,
               "South West":1,
                "Wales":1
                }
keys["GBR"]['location_name2'] = keys["GBR"]['ADMIN_NAME'].map(clim_dic_GBR)
keys["GBR"]['weight'] = keys["GBR"]['ADMIN_NAME'].map(weights_dic_GBR)
cw['GBR'] = keys['GBR'].merge(crosswalk[crosswalk.iso == 'GBR'],
                  on = ["location_name2"], 
                  how = "right")

for iso in countries:
    cw[iso].to_csv(paths.DB + "/Global ACP/labor/1_preparation/crosswalks/timeuse_climate_crosswalk_" + iso + ".csv", index = False)
   

#cw['IND'].to_csv(paths.DB + "/Global ACP/labor/1_preparation/crosswalks/timeuse_climate_crosswalk_" + "IND" + ".csv", index = False)


# CHN crosswalk

from pandas import ExcelFile
paths = cilpath.Cilpath()
dt = {}
cw = {}
merged = {}
cw_folder = paths.DB + "/Global ACP/labor/1_preparation/time_use/china"
cw_not_ipums = pd.read_csv(cw_folder + "/shapefile/CHN_adm2_names.csv")
cw_chns = pd.read_excel(cw_folder + '/crosswalks/commid_调查点.xlsx', sheet_name='Sheet')
dt_chns = pd.read_csv(cw_folder + "/chn_time_use.csv")
cw_not_ipums['NAME_1_lower'] = cw_not_ipums['NAME_1'].str.lower()
cw_not_ipums['NAME_2_lower'] = cw_not_ipums['NAME_2'].str.lower()
cw_chns = cw_chns[['Province_en','City_en','Commid']]
cw_chns.loc[cw_chns.City_en == "qiannan buyi and miao", 'City_en'] = "qiannan buyei and miao"
cw = cw_chns.merge(cw_not_ipums, 
                   left_on =['Province_en', 'City_en'], 
                   right_on = ['NAME_1_lower', 'NAME_2_lower'],
                   how = 'left', indicator = True)
cw["location_id2"] = cw['City_en'].astype('category').cat.codes + 10000
cw["location_id1"] = cw['Province_en'].astype('category').cat.codes + 20000
cw.drop_duplicates()[['Commid','NAME_1','NAME_2','location_id1','location_id2']].to_csv(paths.DB + "/Global ACP/labor/1_preparation/crosswalks/timeuse_climate_crosswalk_" + 'CHN' + ".csv", index = False)
